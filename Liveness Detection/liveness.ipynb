{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2435.42s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2441.30s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (3.7.0)\n",
      "Requirement already satisfied: absl-py in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from keras) (3.12.1)\n",
      "Requirement already satisfied: optree in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from keras) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from keras) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2447.09s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (1.26.4)\n",
      "Requirement already satisfied: mediapipe in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (0.10.18)\n",
      "Requirement already satisfied: scipy in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (1.13.1)\n",
      "Requirement already satisfied: opencv-python in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: absl-py in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from mediapipe) (24.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from mediapipe) (0.4.30)\n",
      "Requirement already satisfied: jaxlib in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from mediapipe) (0.4.30)\n",
      "Requirement already satisfied: matplotlib in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from mediapipe) (3.9.3)\n",
      "Requirement already satisfied: opencv-contrib-python in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from mediapipe) (4.25.5)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from jax->mediapipe) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from jax->mediapipe) (8.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (4.55.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (6.4.5)\n",
      "Requirement already satisfied: pycparser in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.6->jax->mediapipe) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2452.85s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: dlib in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (19.22.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow\n",
    "!pip3 install keras\n",
    "!pip3 install numpy mediapipe scipy opencv-python\n",
    "!pip3 install dlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average variability: 10.047567055302231\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "import dlib  # For landmark detection\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "\n",
    "\n",
    "# --- Optical Flow for Motion Detection ---\n",
    "def compute_optical_flow(prev_gray, frame_gray):\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, frame_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    return flow\n",
    "\n",
    "# --- Eye Blink Detection (using dlib's landmarks) ---\n",
    "def detect_blinks(landmarks, eye_thresh=0.3):\n",
    "    # Extract left and right eye landmarks\n",
    "    left_eye = [landmarks.part(i) for i in range(36, 42)]\n",
    "    right_eye = [landmarks.part(i) for i in range(42, 48)]\n",
    "\n",
    "    # Compute eye aspect ratios\n",
    "    left_eye_ratio = eye_aspect_ratio(left_eye)\n",
    "    right_eye_ratio = eye_aspect_ratio(right_eye)\n",
    "    \n",
    "    if left_eye_ratio < eye_thresh or right_eye_ratio < eye_thresh:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    # Convert dlib points to NumPy arrays (or tuples)\n",
    "    eye = np.array([(point.x, point.y) for point in eye])\n",
    "\n",
    "    A = np.linalg.norm(eye[1] - eye[5])\n",
    "    B = np.linalg.norm(eye[2] - eye[4])\n",
    "    C = np.linalg.norm(eye[0] - eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "def estimate_head_pose(landmarks):\n",
    "    # 2D image points (for head pose estimation)\n",
    "    image_points = np.array([\n",
    "        (landmarks[30].x, landmarks[30].y),  # Nose tip\n",
    "        (landmarks[8].x, landmarks[8].y),    # Chin\n",
    "        (landmarks[36].x, landmarks[36].y),  # Left eye left corner\n",
    "        (landmarks[45].x, landmarks[45].y),  # Right eye right corner\n",
    "        (landmarks[48].x, landmarks[48].y),  # Left mouth corner\n",
    "        (landmarks[54].x, landmarks[54].y)   # Right mouth corner\n",
    "    ], dtype=\"double\")\n",
    "\n",
    "    # 3D model points for head pose estimation\n",
    "    model_points = np.array([\n",
    "        (0.0, 0.0, 0.0),       # Nose tip\n",
    "        (0.0, -330.0, -65.0),  # Chin\n",
    "        (-225.0, 170.0, -135.0),  # Left eye left corner\n",
    "        (225.0, 170.0, -135.0),   # Right eye right corner\n",
    "        (-150.0, -150.0, -125.0), # Left mouth corner\n",
    "        (150.0, -150.0, -125.0)   # Right mouth corner\n",
    "    ])\n",
    "\n",
    "    # Camera internals\n",
    "    size = (640, 480)\n",
    "    focal_length = size[0]\n",
    "    center = (size[0] / 2, size[1] / 2)\n",
    "    camera_matrix = np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    dist_coeffs = np.zeros((4, 1))  # Assuming no lens distortion\n",
    "\n",
    "    _, rotation_vector, translation_vector = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs)\n",
    "\n",
    "    return rotation_vector, translation_vector\n",
    "\n",
    "# --- Helper functions for Motion Detection ---\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def bandpass_filter(data, lowcut=0.7, highcut=4.0, fs=30, order=5):\n",
    "    \"\"\"Bandpass filter for heart rate signal\"\"\"\n",
    "    if len(data) < 2 * order:  # Ensure enough data for filtering\n",
    "        return data  # Return the original signal if it's too short for filtering\n",
    "\n",
    "    # Create bandpass filter coefficients\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order)\n",
    "    \n",
    "    # Apply filter if the signal is long enough\n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "def extract_roi(frame, face_cascade):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(100, 100))\n",
    "    return faces\n",
    "\n",
    "def extract_rppg_signal(roi):\n",
    "    roi = cv2.resize(roi, (100, 100))  # Resize to standard dimensions\n",
    "    green_channel = roi[:, :, 1]  # Extract the green channel\n",
    "    rppg_signal = np.mean(green_channel, axis=0)  # Compute mean across rows\n",
    "    return rppg_signal\n",
    "\n",
    "# def estimate_heart_rate(rppg_signal, fps):\n",
    "#     # Perform FastICA to remove motion artifacts\n",
    "#     ica = FastICA(n_components=1)\n",
    "#     rppg_cleaned = ica.fit_transform(rppg_signal.reshape(-1, 1))\n",
    "\n",
    "#     # Find peaks in the rPPG signal\n",
    "#     peaks, _ = find_peaks(rppg_cleaned[:, 0], height=0.5)\n",
    "\n",
    "#     # Calculate heart rate in beats per minute (BPM)\n",
    "#     heart_rate = len(peaks) / (len(rppg_cleaned) / fps) * 60\n",
    "\n",
    "#     return heart_rate, rppg_cleaned\n",
    "\n",
    "def estimate_heart_rate(rppg_signal, fps, window_size=60, lowcut=0.7, highcut=4.0, peak_distance=15, peak_height=0.2):\n",
    "    \"\"\"Estimate heart rate from a moving window of RPPG signals\"\"\"\n",
    "    if len(rppg_signal) < window_size:\n",
    "        return None, None  # Not enough data for a window of size 30\n",
    "    \n",
    "    # Debugging: Plot the raw RPPG signal to inspect its quality\n",
    "    # plt.figure(figsize=(12, 6))\n",
    "    # plt.subplot(2, 1, 2)\n",
    "    # plt.plot(rppg_signal)\n",
    "    # plt.title(\"Raw RPPG Signal\")\n",
    "\n",
    "    # Accumulate RPPG signal over a window of frames\n",
    "    windowed_signal = rppg_signal[-window_size:]\n",
    "    \n",
    "    # Bandpass filter the accumulated signal to isolate heart rate frequencies\n",
    "    filtered_signal = bandpass_filter(windowed_signal, lowcut=lowcut, highcut=highcut, fs=fps)\n",
    "    \n",
    "    # Debugging: Plot the filtered signal to visualize it\n",
    "    # plt.subplot(2, 1, 2)\n",
    "    # plt.plot(filtered_signal)\n",
    "    # plt.title(f\"Filtered Signal (lowcut={lowcut} Hz, highcut={highcut} Hz)\")\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    # Find peaks and calculate heart rate\n",
    "    peaks, _ = find_peaks(filtered_signal, distance=peak_distance, height=peak_height)  # Minimum peak distance ~0.5 seconds\n",
    "    \n",
    "    # Debugging: Show peaks found on the filtered signal\n",
    "    # plt.plot(filtered_signal)\n",
    "    # plt.plot(peaks, filtered_signal[peaks], 'ro')\n",
    "    # plt.title(f\"Filtered Signal with Detected Peaks (distance={peak_distance}, height={peak_height})\")\n",
    "    # plt.show()\n",
    "\n",
    "    # Calculate heart rate if peaks are detected\n",
    "    if len(peaks) > 1:\n",
    "        heart_rate = len(peaks) / (len(filtered_signal) / fps) * 60\n",
    "        return heart_rate, filtered_signal\n",
    "    return None, None\n",
    "\n",
    "def motion_threshold(roi, previous_roi, motion_threshold=0.01):\n",
    "    \"\"\"Calculate motion based on previous ROI and current frame\"\"\"\n",
    "    if previous_roi is None:\n",
    "        return False\n",
    "\n",
    "    # Resize both ROIs to the same size\n",
    "    roi_resized = cv2.resize(roi, (previous_roi.shape[1], previous_roi.shape[0]))\n",
    "\n",
    "    # Convert both ROIs to grayscale\n",
    "    roi_gray = cv2.cvtColor(roi_resized, cv2.COLOR_BGR2GRAY)\n",
    "    previous_roi_gray = cv2.cvtColor(previous_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Compute absolute difference between the current and previous frame\n",
    "    diff = cv2.absdiff(previous_roi_gray, roi_gray)\n",
    "\n",
    "    # Calculate motion score by summing pixel differences and normalizing by ROI size\n",
    "    motion_score = np.sum(diff) / float(roi_resized.size)\n",
    "\n",
    "    return motion_score > motion_threshold\n",
    "\n",
    "\n",
    "def compute_variability(filtered_signal):\n",
    "    \"\"\"Calculate heart rate variability\"\"\"\n",
    "    if filtered_signal is None or len(filtered_signal) < 2:\n",
    "        return 0\n",
    "    # Variability is the standard deviation of the heart rate signal\n",
    "    return np.std(filtered_signal)\n",
    "\n",
    "def analyze_texture(roi):\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    texture_score = laplacian.var()  # Variance of Laplacian\n",
    "    return texture_score > 30  # Lower texture variance threshold for real faces\n",
    "\n",
    "def analyze_focus(roi):\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    focus_score = laplacian.var()  # Variance of Laplacian\n",
    "    return focus_score > 10  # Looser focus threshold to allow more real faces\n",
    "\n",
    "# mp_face_mesh = mp.solutions.face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# def detect_face_landmarks(frame):\n",
    "#     rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#     results = mp_face_mesh.process(rgb_frame)\n",
    "#     if results.multi_face_landmarks:\n",
    "#         return results.multi_face_landmarks[0]\n",
    "#     return None\n",
    "\n",
    "def evaluate_liveness(heart_rate, variability, motion_detected, texture_score, focus_detected, blink_detected, confidence_threshold=0.6):\n",
    "    \"\"\"Evaluate liveness based on heart rate, motion, texture, focus, and blink detection\"\"\"\n",
    "    motion_weight = 0.15\n",
    "    texture_weight = 0.15\n",
    "    heart_rate_weight = 0.25\n",
    "    focus_weight = 0.2\n",
    "    blink_weight = 0.25\n",
    "\n",
    "    alive_count = 0\n",
    "    if motion_detected:\n",
    "        alive_count += 1\n",
    "    if texture_score:\n",
    "        alive_count += 1\n",
    "    if heart_rate and 50 <= heart_rate <= 100:\n",
    "        alive_count += 1\n",
    "    if focus_detected:\n",
    "        alive_count += 1\n",
    "    if blink_detected:\n",
    "        alive_count += 1\n",
    "\n",
    "    score = (motion_weight * motion_detected) + (texture_weight * texture_score) + (heart_rate_weight * (heart_rate is not None and 50 <= heart_rate <= 100)) + (focus_weight * focus_detected) + (blink_weight * blink_detected)\n",
    "\n",
    "    if (alive_count >= 3 or score >= 40) and variability < 6:  # Deepfake variability threshold\n",
    "        return \"Alive\", True\n",
    "    return \"Negative\", False\n",
    "\n",
    "\n",
    "\n",
    "# --- Main program ---\n",
    "variability_sum = 0 \n",
    "frame_count = 0\n",
    "try:\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    fps = 30\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(\"Error: Could not open webcam.\")\n",
    "\n",
    "    previous_roi = None\n",
    "    previous_gray = None\n",
    "    previous_landmarks = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(100, 100))\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            roi = frame[y:y+h, x:x+w]\n",
    "            if previous_roi is not None:\n",
    "                motion_detected = motion_threshold(roi, previous_roi)\n",
    "            else:\n",
    "                motion_detected = False\n",
    "\n",
    "                # landmarks = detect_face_landmarks(frame)\n",
    "                # if not landmarks:\n",
    "                #     return \"No face detected\", False\n",
    "                \n",
    "                # # Extract features (blink detection, motion, etc.)\n",
    "                # blink_detected = analyze_blink(landmarks)\n",
    "                # heart_rate = estimate_heart_rate(rppg_signal, fps)\n",
    "                # focus_score = analyze_focus(roi)\n",
    "                # motion_score = motion_threshold(roi, previous_roi)\n",
    "                \n",
    "                # # Use ML model for decision\n",
    "                # features = [blink_detected, heart_rate, motion_score, focus_score]\n",
    "                # is_alive = model.predict(features)\n",
    "                # return \"Alive\" if is_alive else \"Fake\", is_alive\n",
    "\n",
    "            # Use dlib to detect landmarks and blink detection\n",
    "            landmarks = predictor(gray, dlib.rectangle(x, y, x+w, y+h))\n",
    "            blink_detected = detect_blinks(landmarks)\n",
    "            \n",
    "            # Estimate heart rate from RPPG signal\n",
    "            rppg_signal = extract_rppg_signal(roi)\n",
    "            heart_rate, filtered_signal = estimate_heart_rate(rppg_signal, fps)\n",
    "            variability = compute_variability(filtered_signal)\n",
    "\n",
    "            variability_sum += variability\n",
    "            frame_count+=1\n",
    "\n",
    "            # Analyze texture and focus\n",
    "            texture_score = analyze_texture(roi)\n",
    "            focus_detected = analyze_focus(roi)\n",
    "\n",
    "            # Evaluate liveness\n",
    "            status, is_alive = evaluate_liveness(heart_rate, variability, motion_detected, texture_score, focus_detected, blink_detected)\n",
    "            # print(f\"Status: {status}, Heart Rate: {heart_rate}, Variability: {variability}, motion_detected: {motion_detected}, texture_score: {texture_score}, texture_score: {texture_score}, blink_detected: {blink_detected}\")\n",
    "\n",
    "            previous_roi = roi\n",
    "            previous_gray = gray\n",
    "            previous_landmarks = landmarks\n",
    "\n",
    "            # Draw rectangle around the face\n",
    "            color = (0, 255, 0) if is_alive else (0, 0, 255)  # Green for alive, red for deep fake\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "\n",
    "            # Display heart rate and liveness status on the frame\n",
    "            # cv2.putText(frame, f\"Heart Rate: {heart_rate if heart_rate else 'N/A'} bpm\", (x, y - 30),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "            cv2.putText(frame, f\"Liveness: {status}\", (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "            # Display the resulting frame\n",
    "            cv2.imshow('Frame', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print (f\"average variability: {variability_sum/frame_count}\")\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
