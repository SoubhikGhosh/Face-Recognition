{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: No matching packages\u001b[0m\u001b[33m\n",
      "\u001b[0mFiles removed: 0\n"
     ]
    }
   ],
   "source": [
    "!pip3 cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (0.17.2)\n",
      "Requirement already satisfied: filelock in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: numpy in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (2.18.0)\n",
      "Requirement already satisfied: opencv-python-headless in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: dlib in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (19.24.6)\n",
      "Requirement already satisfied: face_recognition in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (1.3.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (1.5.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from face_recognition) (8.1.7)\n",
      "Requirement already satisfied: Pillow in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from face_recognition) (10.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow opencv-python-headless dlib face_recognition scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: facenet-pytorch in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from facenet-pytorch) (1.26.4)\n",
      "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from facenet-pytorch) (10.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from facenet-pytorch) (2.32.3)\n",
      "Requirement already satisfied: torch<2.3.0,>=2.2.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from facenet-pytorch) (2.2.2)\n",
      "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from facenet-pytorch) (0.17.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from facenet-pytorch) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2024.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install facenet-pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detector\n",
    "mtcnn = MTCNN(keep_all=True, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Face recognition model (FaceNet pre-trained)\n",
    "facenet = InceptionResnetV1(pretrained='vggface2').eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(image, mtcnn, target_size=(160, 160)):\n",
    "    \"\"\"\n",
    "    Detects and crops the face from the image.\n",
    "    \"\"\"\n",
    "    boxes, _ = mtcnn.detect(image)\n",
    "    if boxes is None:\n",
    "        return None\n",
    "    cropped_faces = []\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = [int(b) for b in box]\n",
    "        face = image[y1:y2, x1:x2]\n",
    "        face_resized = cv2.resize(face, target_size)\n",
    "        cropped_faces.append(face_resized)\n",
    "    return cropped_faces\n",
    "\n",
    "def encode_faces(faces, facenet):\n",
    "    \"\"\"\n",
    "    Generates embeddings for detected faces.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    for face in faces:\n",
    "        # Convert to PyTorch tensor\n",
    "        face = torch.tensor(face.transpose(2, 0, 1)).float().unsqueeze(0) / 255.0\n",
    "        embedding = facenet(face).detach().numpy()\n",
    "        embeddings.append(embedding)\n",
    "    return np.vstack(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_faces(input_image, database, mtcnn, facenet, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Recognizes faces in the input image by comparing with the database.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_image: The image to process.\n",
    "    - database: A dictionary of precomputed embeddings (name -> embedding).\n",
    "    - mtcnn: The face detector.\n",
    "    - facenet: The face recognition model.\n",
    "    - threshold: Similarity threshold for recognition.\n",
    "    \n",
    "    Returns:\n",
    "    - Annotated image with recognition results.\n",
    "    \"\"\"\n",
    "    # Detect and crop faces\n",
    "    faces = extract_face(input_image, mtcnn)\n",
    "    if not faces:\n",
    "        return input_image, []\n",
    "    \n",
    "    # Generate embeddings\n",
    "    embeddings = encode_faces(faces, facenet)\n",
    "    \n",
    "    # Compare with database\n",
    "    results = []\n",
    "    for emb in embeddings:\n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        for name, db_emb in database.items():\n",
    "            score = cosine_similarity([emb], [db_emb])[0, 0]\n",
    "            if score > best_score and score > threshold:\n",
    "                best_match = name\n",
    "                best_score = score\n",
    "        results.append((best_match, best_score))\n",
    "    \n",
    "    # Annotate image\n",
    "    annotated_image = input_image.copy()\n",
    "    for (box, (name, score)) in zip(mtcnn.detect(input_image)[0], results):\n",
    "        x1, y1, x2, y2 = [int(b) for b in box]\n",
    "        label = f\"{name} ({score:.2f})\" if name else \"Unknown\"\n",
    "        color = (0, 255, 0) if name else (0, 0, 255)\n",
    "        cv2.rectangle(annotated_image, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(annotated_image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "    return annotated_image, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_face_database(image_folder, mtcnn, facenet):\n",
    "    \"\"\"\n",
    "    Creates a database of known faces from images in the given folder.\n",
    "    \"\"\"\n",
    "    database = {}\n",
    "    for file in os.listdir(image_folder):\n",
    "        name, ext = os.path.splitext(file)\n",
    "        if ext.lower() not in ['.jpg', '.png']:\n",
    "            continue\n",
    "        image = cv2.imread(os.path.join(image_folder, file))\n",
    "        faces = extract_face(image, mtcnn)\n",
    "        if faces:\n",
    "            embeddings = encode_faces(faces, facenet)\n",
    "            database[name] = embeddings[0]\n",
    "    return database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@36.447] global loadsave.cpp:241 findDecoder imread_('chris_test.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Process a test image\u001b[39;00m\n\u001b[1;32m      5\u001b[0m input_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchris_test.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m annotated_image, results \u001b[38;5;241m=\u001b[39m \u001b[43mrecognize_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmtcnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfacenet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[1;32m      9\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFace Recognition\u001b[39m\u001b[38;5;124m\"\u001b[39m, annotated_image)\n",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m, in \u001b[0;36mrecognize_faces\u001b[0;34m(input_image, database, mtcnn, facenet, threshold)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mRecognizes faces in the input image by comparing with the database.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m- Annotated image with recognition results.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Detect and crop faces\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[43mextract_face\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmtcnn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m faces:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m input_image, []\n",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m, in \u001b[0;36mextract_face\u001b[0;34m(image, mtcnn, target_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_face\u001b[39m(image, mtcnn, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m160\u001b[39m, \u001b[38;5;241m160\u001b[39m)):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Detects and crops the face from the image.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     boxes, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmtcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m boxes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/facenet_pytorch/models/mtcnn.py:313\u001b[0m, in \u001b[0;36mMTCNN.detect\u001b[0;34m(self, img, landmarks)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Detect all faces in PIL image and return bounding boxes and optional facial landmarks.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03mThis method is used by the forward method and is also useful for face detection tasks\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m>>> img_draw.save('annotated_faces.png')\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 313\u001b[0m     batch_boxes, batch_points \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_face\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_face_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthresholds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m boxes, probs, points \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m box, point \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batch_boxes, batch_points):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/facenet_pytorch/models/utils/detect_face.py:38\u001b[0m, in \u001b[0;36mdetect_face\u001b[0;34m(imgs, minsize, pnet, rnet, onet, threshold, factor, device)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(imgs, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m     37\u001b[0m     imgs \u001b[38;5;241m=\u001b[39m [imgs]\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMTCNN batch processing only compatible with equal-dimension images.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m imgs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([np\u001b[38;5;241m.\u001b[39muint8(img) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m imgs])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/facenet_pytorch/models/utils/detect_face.py:38\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(imgs, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m     37\u001b[0m     imgs \u001b[38;5;241m=\u001b[39m [imgs]\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m \u001b[38;5;241m!=\u001b[39m imgs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m imgs):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMTCNN batch processing only compatible with equal-dimension images.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m imgs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([np\u001b[38;5;241m.\u001b[39muint8(img) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m imgs])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'size'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load known faces\n",
    "database = build_face_database(\"known_faces\", mtcnn, facenet)\n",
    "\n",
    "# Process a test image\n",
    "input_image = cv2.imread(\"chris_test.jpg\")\n",
    "annotated_image, results = recognize_faces(input_image, database, mtcnn, facenet)\n",
    "\n",
    "# Display results\n",
    "cv2.imshow(\"Face Recognition\", annotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
